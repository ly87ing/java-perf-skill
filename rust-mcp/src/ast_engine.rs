//! AST Engine - é«˜æ€§èƒ½æ­£åˆ™åˆ†æ + æ³¨é‡Šè¿‡æ»¤
//!
//! ğŸ›°ï¸ é›·è¾¾æ‰«æï¼šæ£€æµ‹æ€§èƒ½åæ¨¡å¼
//!
//! ä¼˜åŒ–ç‚¹ï¼š
//! 1. ä½¿ç”¨ once_cell é™æ€ç¼–è¯‘æ­£åˆ™ï¼Œé¿å…é‡å¤åˆ›å»º
//! 2. è¿‡æ»¤æ³¨é‡Šå†…å®¹ï¼Œé¿å…è¯¯æŠ¥
//! 3. æ–°å¢å“åº”å¼ç¼–ç¨‹é—®é¢˜æ£€æµ‹
//! 4. é›†æˆ Tree-sitter AST åˆ†æ (v5.0)
//! 5. å¹¶è¡Œæ–‡ä»¶æ‰«æ (rayon) (v5.1)
//! 6. Dockerfile æ‰«æ (v5.1)

use once_cell::sync::Lazy;
use regex::Regex;
use serde_json::{json, Value};
use std::path::Path;
use std::sync::Mutex;
use walkdir::WalkDir;
use rayon::prelude::*;

use crate::scanner::{CodeAnalyzer, Issue as ScannerIssue, Severity as ScannerSeverity};
use crate::scanner::tree_sitter_java::JavaTreeSitterAnalyzer;
use crate::scanner::config::LineBasedConfigAnalyzer;
use crate::scanner::dockerfile::DockerfileAnalyzer;

// ============================================================================
// é™æ€ç¼–è¯‘æ­£åˆ™è¡¨è¾¾å¼ï¼ˆåªç¼–è¯‘ä¸€æ¬¡ï¼Œå…¨å±€å¤ç”¨ï¼‰
// ============================================================================

/// æ³¨é‡ŠåŒ¹é…æ­£åˆ™ï¼ˆç”¨äºè¿‡æ»¤ï¼‰
static COMMENT_REGEX: Lazy<Regex> = Lazy::new(|| {
    Regex::new(r"//.*$|/\*[\s\S]*?\*/").unwrap()
});

// P0 ä¸¥é‡è§„åˆ™
static RE_N_PLUS_ONE: Lazy<Regex> = Lazy::new(|| {
    Regex::new(r"(?i)for\s*\([^)]+\)\s*\{[^}]*(dao|repository|mapper|jdbc|select|insert|update|delete|http|client)[^}]*\}").unwrap()
});
static RE_NESTED_LOOP: Lazy<Regex> = Lazy::new(|| {
    Regex::new(r"for\s*\([^)]+\)\s*\{[^}]*for\s*\([^)]+\)").unwrap()
});
static RE_SYNC_METHOD: Lazy<Regex> = Lazy::new(|| {
    Regex::new(r"public\s+synchronized\s+\w+\s+\w+\s*\(").unwrap()
});
static RE_THREADLOCAL: Lazy<Regex> = Lazy::new(|| {
    Regex::new(r"ThreadLocal\s*<").unwrap()
});
static RE_UNBOUNDED_POOL: Lazy<Regex> = Lazy::new(|| {
    Regex::new(r"Executors\s*\.\s*(newCachedThreadPool|newScheduledThreadPool|newSingleThreadExecutor)").unwrap()
});
static RE_UNBOUNDED_CACHE_MAP: Lazy<Regex> = Lazy::new(|| {
    Regex::new(r"static\s+.*Map\s*<[^>]+>\s*\w+\s*=\s*new").unwrap()
});
static RE_UNBOUNDED_CACHE_LIST: Lazy<Regex> = Lazy::new(|| {
    Regex::new(r"static\s+.*(List|Set)\s*<[^>]+>\s*\w+\s*=\s*new").unwrap()
});
static RE_EXCEPTION_IGNORE: Lazy<Regex> = Lazy::new(|| {
    Regex::new(r"catch\s*\([^)]+\)\s*\{\s*\}").unwrap()
});

// P1 è­¦å‘Šè§„åˆ™
static RE_OBJECT_IN_LOOP: Lazy<Regex> = Lazy::new(|| {
    Regex::new(r"for\s*\([^)]+\)\s*\{[^}]*new\s+\w+\s*\(").unwrap()
});
static RE_SYNC_BLOCK: Lazy<Regex> = Lazy::new(|| {
    Regex::new(r"synchronized\s*\([^)]+\)\s*\{").unwrap()
});
static RE_ATOMIC_SPIN: Lazy<Regex> = Lazy::new(|| {
    Regex::new(r"(AtomicInteger|AtomicLong)\s*[<\s]").unwrap()
});
static RE_NO_TIMEOUT: Lazy<Regex> = Lazy::new(|| {
    Regex::new(r"(HttpClient|RestTemplate|OkHttp|WebClient)\s*\.").unwrap()
});
static RE_BLOCKING_IO: Lazy<Regex> = Lazy::new(|| {
    Regex::new(r"new\s+File(Input|Output)Stream").unwrap()
});
static RE_STRING_CONCAT: Lazy<Regex> = Lazy::new(|| {
    Regex::new(r"for\s*\([^)]+\)\s*\{[^}]*\+=").unwrap()
});
static RE_EXCEPTION_SWALLOW: Lazy<Regex> = Lazy::new(|| {
    Regex::new(r"catch\s*\([^)]+\)\s*\{[^}]*\.print").unwrap()
});

// å“åº”å¼ç¼–ç¨‹é—®é¢˜ (æ¥è‡ª MMS æŠ¥å‘Š)
static RE_EMITTER_UNBOUNDED: Lazy<Regex> = Lazy::new(|| {
    Regex::new(r"EmitterProcessor\s*\.\s*create\s*\(\s*\)").unwrap()
});
static RE_SINKS_NO_BACKPRESSURE: Lazy<Regex> = Lazy::new(|| {
    Regex::new(r"Sinks\s*\.\s*many\s*\(\s*\)").unwrap()
});

// ç¼“å­˜é…ç½®é—®é¢˜
static RE_CACHE_NO_EXPIRE: Lazy<Regex> = Lazy::new(|| {
    Regex::new(r"(Caffeine|CacheBuilder)\s*\.\s*newBuilder").unwrap()
});

// ============================================================================
// è§„åˆ™å®šä¹‰
// ============================================================================

/// é—®é¢˜ä¸¥é‡çº§åˆ«
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum Severity {
    P0, // ä¸¥é‡
    P1, // è­¦å‘Š
}

/// AST æ£€æµ‹é—®é¢˜
#[derive(Debug)]
pub struct AstIssue {
    pub severity: Severity,
    pub issue_type: String,
    pub file: String,
    pub line: usize,
    pub description: String,
}

/// è§„åˆ™é…ç½®
struct Rule {
    id: &'static str,
    description: &'static str,
    severity: Severity,
    regex: &'static Lazy<Regex>,
}

/// æ‰€æœ‰è§„åˆ™ï¼ˆå¼•ç”¨é™æ€ç¼–è¯‘çš„æ­£åˆ™ï¼‰
fn get_rules() -> Vec<Rule> {
    vec![
        // AST Migrated Rules (Commented out / handled by Tree-sitter)
        // Rule { id: "N_PLUS_ONE", ... }
        // Rule { id: "NESTED_LOOP", ... }
        // Rule { id: "SYNC_METHOD", ... }
        
        // P0 ä¸¥é‡
        Rule { id: "UNBOUNDED_POOL", description: "æ— ç•Œçº¿ç¨‹æ±  Executors", severity: Severity::P0, regex: &RE_UNBOUNDED_POOL },
        Rule { id: "UNBOUNDED_CACHE", description: "æ— ç•Œç¼“å­˜ static Map", severity: Severity::P0, regex: &RE_UNBOUNDED_CACHE_MAP },
        Rule { id: "UNBOUNDED_LIST", description: "æ— ç•Œç¼“å­˜ static List/Set", severity: Severity::P0, regex: &RE_UNBOUNDED_CACHE_LIST },
        Rule { id: "EXCEPTION_IGNORE", description: "ç©º catch å—", severity: Severity::P0, regex: &RE_EXCEPTION_IGNORE },
        Rule { id: "EMITTER_UNBOUNDED", description: "EmitterProcessor æ— ç•Œ (èƒŒå‹é—®é¢˜)", severity: Severity::P0, regex: &RE_EMITTER_UNBOUNDED },
        // P1 è­¦å‘Š
        Rule { id: "OBJECT_IN_LOOP", description: "å¾ªç¯å†…åˆ›å»ºå¯¹è±¡", severity: Severity::P1, regex: &RE_OBJECT_IN_LOOP },
        Rule { id: "SYNC_BLOCK", description: "synchronized ä»£ç å—", severity: Severity::P1, regex: &RE_SYNC_BLOCK },
        Rule { id: "ATOMIC_SPIN", description: "Atomic è‡ªæ—‹ (è€ƒè™‘ LongAdder)", severity: Severity::P1, regex: &RE_ATOMIC_SPIN },
        Rule { id: "NO_TIMEOUT", description: "HTTP å®¢æˆ·ç«¯å¯èƒ½æ— è¶…æ—¶", severity: Severity::P1, regex: &RE_NO_TIMEOUT },
        Rule { id: "BLOCKING_IO", description: "åŒæ­¥æ–‡ä»¶ IO", severity: Severity::P1, regex: &RE_BLOCKING_IO },
        Rule { id: "STRING_CONCAT", description: "å¾ªç¯å†…å­—ç¬¦ä¸²æ‹¼æ¥", severity: Severity::P1, regex: &RE_STRING_CONCAT },
        Rule { id: "EXCEPTION_SWALLOW", description: "å¼‚å¸¸è¢«åæ²¡ (ä»…æ‰“å°)", severity: Severity::P1, regex: &RE_EXCEPTION_SWALLOW },
        Rule { id: "SINKS_NO_BACKPRESSURE", description: "Sinks.many() æ— èƒŒå‹å¤„ç†", severity: Severity::P1, regex: &RE_SINKS_NO_BACKPRESSURE },
        Rule { id: "CACHE_NO_EXPIRE", description: "Cache å¯èƒ½æ— è¿‡æœŸé…ç½®", severity: Severity::P1, regex: &RE_CACHE_NO_EXPIRE },
    ]
}

// Helper to convert ScannerIssue to AstIssue
fn convert_issue(issue: ScannerIssue) -> AstIssue {
    let sev = match issue.severity {
        ScannerSeverity::P0 => Severity::P0,
        ScannerSeverity::P1 => Severity::P1,
    };
    AstIssue {
        severity: sev,
        issue_type: issue.id,
        file: issue.file,
        line: issue.line,
        description: issue.description,
    }
}

// ============================================================================
// æ ¸å¿ƒæ‰«æå‡½æ•°
// ============================================================================

/// å…¨é¡¹ç›®é›·è¾¾æ‰«æ (v5.1 å¹¶è¡Œç‰ˆæœ¬)
/// 
/// compact: true æ—¶åªè¿”å› P0ï¼Œæ¯ä¸ª issue åªæœ‰ id/file/line
/// max_p1: compact=false æ—¶æœ€å¤šè¿”å›çš„ P1 æ•°é‡
pub fn radar_scan(code_path: &str, compact: bool, max_p1: usize) -> Result<Value, Box<dyn std::error::Error>> {
    let path = Path::new(code_path);
    
    // æ”¶é›†æ‰€æœ‰å¾…æ‰«ææ–‡ä»¶
    let entries: Vec<_> = WalkDir::new(path)
        .follow_links(true)
        .into_iter()
        .filter_map(|e| e.ok())
        .filter(|e| e.file_type().is_file())
        .collect();

    let file_count = entries.len();

    // ä½¿ç”¨ Mutex ä¿æŠ¤å…±äº«çŠ¶æ€ (rayon å¹¶è¡Œå®‰å…¨)
    let issues: Mutex<Vec<AstIssue>> = Mutex::new(Vec::new());

    // é¢„åˆå§‹åŒ–åˆ†æå™¨ (åœ¨å¹¶è¡Œå‰åˆ›å»ºï¼Œæ¯ä¸ªçº¿ç¨‹å…‹éš†ä½¿ç”¨æˆ–æŒ‰éœ€åˆ›å»º)
    // æ³¨æ„ï¼šç”±äº Tree-sitter çš„ Query ä¸æ˜¯ Sendï¼Œæˆ‘ä»¬åœ¨æ¯ä¸ªçº¿ç¨‹å†…åˆ›å»ºåˆ†æå™¨

    // å¹¶è¡Œå¤„ç†æ–‡ä»¶
    entries.par_iter().for_each(|entry| {
        let file_path = entry.path();
        let file_name_str = file_path.file_name()
            .map(|n| n.to_string_lossy().to_string())
            .unwrap_or_default();
        let ext = file_path.extension().and_then(|e| e.to_str()).unwrap_or("");

        // æœ¬çº¿ç¨‹çš„ issues
        let mut local_issues: Vec<AstIssue> = Vec::new();

        if ext == "java" {
            if let Ok(content) = std::fs::read_to_string(file_path) {
                // 1. Regex Analysis (Legacy)
                let legacy = analyze_java_code(&content, &file_path.to_string_lossy());
                local_issues.extend(legacy);

                // 2. AST Analysis
                if let Ok(analyzer) = JavaTreeSitterAnalyzer::new() {
                    if let Ok(ast_results) = analyzer.analyze(&content, file_path) {
                        local_issues.extend(ast_results.into_iter().map(convert_issue));
                    }
                }
            }
        } else if ["yml", "yaml", "properties"].contains(&ext) {
            if let Ok(content) = std::fs::read_to_string(file_path) {
                // 3. Config Analysis
                if let Ok(analyzer) = LineBasedConfigAnalyzer::new() {
                    if let Ok(config_results) = analyzer.analyze(&content, file_path) {
                        local_issues.extend(config_results.into_iter().map(convert_issue));
                    }
                }
            }
        } else if file_name_str == "Dockerfile" || file_name_str.starts_with("Dockerfile.") {
            if let Ok(content) = std::fs::read_to_string(file_path) {
                // 4. Dockerfile Analysis (v5.1 NEW)
                if let Ok(analyzer) = DockerfileAnalyzer::new() {
                    if let Ok(docker_results) = analyzer.analyze(&content, file_path) {
                        local_issues.extend(docker_results.into_iter().map(convert_issue));
                    }
                }
            }
        }

        // åˆå¹¶åˆ°å…¨å±€ issues
        if !local_issues.is_empty() {
            let mut global = issues.lock().unwrap();
            global.extend(local_issues);
        }
    });

    let issues = issues.into_inner().unwrap();
    let p0_count = issues.iter().filter(|i| matches!(i.severity, Severity::P0)).count();
    let p1_count = issues.iter().filter(|i| matches!(i.severity, Severity::P1)).count();

    // === æ ¹æ® compact æ¨¡å¼ç”Ÿæˆä¸åŒæŠ¥å‘Š ===
    if compact {
        // ç´§å‡‘æ¨¡å¼ï¼šåªè¿”å› P0ï¼Œç²¾ç®€æ ¼å¼
        let mut report = format!(
            "## ğŸ›°ï¸ é›·è¾¾æ‰«æ (v5.1 å¹¶è¡Œ)\n\n**P0**: {} | **P1**: {} | **æ–‡ä»¶**: {}\n\n",
            p0_count, p1_count, file_count
        );

        if p0_count > 0 {
            for issue in issues.iter().filter(|i| matches!(i.severity, Severity::P0)) {
                report.push_str(&format!(
                    "- `{}` {}:{}\n",
                    issue.issue_type, issue.file, issue.line
                ));
            }
        } else {
            report.push_str("âœ… æ—  P0 é—®é¢˜\n");
        }

        if p1_count > 0 {
            report.push_str(&format!("\n*ï¼ˆ{} ä¸ª P1 è­¦å‘Šå·²çœç•¥ï¼Œä½¿ç”¨ compact=false æŸ¥çœ‹ï¼‰*\n", p1_count));
        }

        Ok(json!(report))
    } else {
        // å®Œæ•´æ¨¡å¼
        let mut report = format!(
            "## ğŸ›°ï¸ é›·è¾¾æ‰«æç»“æœ (v5.1 å¹¶è¡Œ + Dockerfile)\n\n\
            **æ‰«æ**: {} ä¸ªæ–‡ä»¶\n\
            **å‘ç°**: {} ä¸ªå«Œç–‘ç‚¹ (P0: {}, P1: {})\n\n",
            file_count, issues.len(), p0_count, p1_count
        );

        if p0_count > 0 {
            report.push_str("### ğŸ”´ P0 ä¸¥é‡å«Œç–‘\n\n");
            for issue in issues.iter().filter(|i| matches!(i.severity, Severity::P0)) {
                report.push_str(&format!(
                    "- **{}** - `{}:{}` - {}\n",
                    issue.issue_type, issue.file, issue.line, issue.description
                ));
            }
            report.push('\n');
        }

        if p1_count > 0 {
            report.push_str(&format!("### ğŸŸ¡ P1 è­¦å‘Š (æ˜¾ç¤ºå‰ {})\n\n", max_p1));
            for issue in issues.iter().filter(|i| matches!(i.severity, Severity::P1)).take(max_p1) {
                report.push_str(&format!(
                    "- **{}** - `{}:{}` - {}\n",
                    issue.issue_type, issue.file, issue.line, issue.description
                ));
            }
        }

        Ok(json!(report))
    }
}

/// å•æ–‡ä»¶æ‰«æ
pub fn scan_source_code(code: &str, file_path: &str) -> Result<Value, Box<dyn std::error::Error>> {
    let mut issues = Vec::new();
    let path = Path::new(file_path);
    let ext = path.extension().and_then(|e| e.to_str()).unwrap_or("");

    if ext == "java" {
        // Regex
        issues.extend(analyze_java_code(code, file_path));
        // AST
        if let Ok(analyzer) = JavaTreeSitterAnalyzer::new() {
             if let Ok(res) = analyzer.analyze(code, path) {
                 issues.extend(res.into_iter().map(convert_issue));
             }
        }
    } else if ["yml", "yaml", "properties"].contains(&ext) {
        // Config
        if let Ok(analyzer) = LineBasedConfigAnalyzer::new() {
             if let Ok(res) = analyzer.analyze(code, path) {
                 issues.extend(res.into_iter().map(convert_issue));
             }
        }
    }

    let mut report = format!("## ğŸ›°ï¸ æ‰«æ: {}\n\n", file_path);

    if issues.is_empty() {
        report.push_str("âœ… æœªå‘ç°æ˜æ˜¾æ€§èƒ½é—®é¢˜\n");
    } else {
        for issue in &issues {
            let emoji = match issue.severity {
                Severity::P0 => "ğŸ”´",
                Severity::P1 => "ğŸŸ¡",
            };
            report.push_str(&format!(
                "{} **{}** (è¡Œ {}) - {}\n",
                emoji, issue.issue_type, issue.line, issue.description
            ));
        }
    }

    Ok(json!(report))
}

/// åˆ†æ Java ä»£ç ï¼ˆé«˜æ€§èƒ½ç‰ˆæœ¬ - Legacy Regexï¼‰
fn analyze_java_code(code: &str, file_path: &str) -> Vec<AstIssue> {
    let mut issues = Vec::new();
    let file_name = Path::new(file_path)
        .file_name()
        .map(|n| n.to_string_lossy().to_string())
        .unwrap_or_else(|| file_path.to_string());

    // 1. ç§»é™¤æ³¨é‡Šï¼Œé¿å…è¯¯æŠ¥
    let code_without_comments = COMMENT_REGEX.replace_all(code, "");

    // 2. ç‰¹æ®Šæ£€æµ‹ï¼šThreadLocal (MIGRATED TO AST -> DISABLED HERE)
    /*
    if RE_THREADLOCAL.is_match(&code_without_comments) {
        if !code_without_comments.contains(".remove()") {
            if let Some(mat) = RE_THREADLOCAL.find(&code_without_comments) {
                let line_num = code_without_comments[..mat.start()].matches('\n').count() + 1;
                issues.push(AstIssue {
                    severity: Severity::P0,
                    issue_type: "THREADLOCAL_LEAK".to_string(),
                    file: file_name.clone(),
                    line: line_num,
                    description: "ThreadLocal æœªè°ƒç”¨ remove()ï¼Œçº¿ç¨‹æ± å¤ç”¨ä¼šå¯¼è‡´å†…å­˜æ³„éœ²".to_string(),
                });
            }
        }
    }
    */

    // 3. ç‰¹æ®Šæ£€æµ‹ï¼šCache éœ€è¦ expire é…ç½®
    if RE_CACHE_NO_EXPIRE.is_match(&code_without_comments) {
        if !code_without_comments.contains("expire") && !code_without_comments.contains("maximumSize") {
            if let Some(mat) = RE_CACHE_NO_EXPIRE.find(&code_without_comments) {
                let line_num = code_without_comments[..mat.start()].matches('\n').count() + 1;
                issues.push(AstIssue {
                    severity: Severity::P1,
                    issue_type: "CACHE_NO_EXPIRE".to_string(),
                    file: file_name.clone(),
                    line: line_num,
                    description: "Caffeine/Guava Cache æœªè®¾ç½® expire æˆ– maximumSize".to_string(),
                });
            }
        }
    }

    // 4. ä½¿ç”¨é™æ€ç¼–è¯‘çš„æ­£åˆ™è¿›è¡ŒåŒ¹é…
    let rules = get_rules();
    for rule in &rules {
        // è·³è¿‡å·²ç‰¹æ®Šå¤„ç†çš„è§„åˆ™
        if rule.id == "CACHE_NO_EXPIRE" {
            continue;
        }

        if rule.regex.is_match(&code_without_comments) {
            if let Some(mat) = rule.regex.find(&code_without_comments) {
                let line_num = code_without_comments[..mat.start()].matches('\n').count() + 1;

                // å»é‡
                let exists = issues.iter().any(|i| i.issue_type == rule.id && i.line == line_num);

                if !exists {
                    issues.push(AstIssue {
                        severity: rule.severity,
                        issue_type: rule.id.to_string(),
                        file: file_name.clone(),
                        line: line_num,
                        description: rule.description.to_string(),
                    });
                }
            }
        }
    }

    issues
}
